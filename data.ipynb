{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VP5NiJw9sDt"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "TRAIN_PATH\n",
        "\n",
        "# train path is for training folder data path\n",
        "\n",
        "\n",
        "TRAIN_IMAGES = glob.glob(TRAIN_PATH + '/*.png')\n",
        "DF_TRAIN = pd.DataFrame(TRAIN_IMAGES, columns = ['image_path'])\n",
        "\n",
        "classes = {0 : 'BLED',\n",
        "           1 : 'NON BLED',\n",
        "           }\n",
        "           import os\n",
        "\n",
        "def get_three_classes(x, y):\n",
        "    # Create a mapping from folder names to class labels\n",
        "    class_mapping = {'0': 0, '1': 1}\n",
        "\n",
        "    # Initialize lists to store filtered data\n",
        "    filtered_x = []\n",
        "    filtered_y = []\n",
        "\n",
        "    # Iterate through the data and filter based on folder names\n",
        "    for i in range(len(x)):\n",
        "        folder_name = os.path.basename(os.path.dirname(x[i]))  # Extract folder name from path\n",
        "        if folder_name in class_mapping:\n",
        "            filtered_x.append(x[i])\n",
        "            filtered_y.append(class_mapping[folder_name])\n",
        "\n",
        "    # Convert to NumPy arrays and one-hot encode labels\n",
        "    filtered_x = np.array(filtered_x)\n",
        "    filtered_y = tf.keras.utils.to_categorical(filtered_y, num_classes=2)\n",
        "\n",
        "    return filtered_x, filtered_y\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(TRAIN_PATH):\n",
        "    # List all files and folders in the specified folder\n",
        "    file_list = os.listdir(TRAIN_PATH)\n",
        "\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(TRAIN_PATH, file_name)\n",
        "        if os.path.isdir(file_path):\n",
        "            print(f\"Folder: {file_name}\")\n",
        "        else:\n",
        "            print(f\"File: {file_name}\")\n",
        "else:\n",
        "    print(\"Folder not found.\")\n",
        "\n",
        "data_path = TRAIN_PATH\n",
        "\n",
        "def get_three_classes(x, y):\n",
        "    unique_classes = np.unique(y)\n",
        "\n",
        "    if 0 in unique_classes and 1 in unique_classes:\n",
        "        indices_0 = np.where(y == 0)[0]\n",
        "        indices_1 = np.where(y == 1)[0]\n",
        "\n",
        "        indices = np.concatenate([indices_0, indices_1], axis=0)\n",
        "\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "        count = x.shape[0]\n",
        "        indices = np.random.choice(range(count), count, replace=False)\n",
        "\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "        y = tf.keras.utils.to_categorical(y)\n",
        "\n",
        "        return x, y\n",
        "    else:\n",
        "        # Handle the case where classes 0 and 1 are not present\n",
        "        print(\"Classes 0 and 1 not found in the data.\")\n",
        "        return None, None\n",
        "\n",
        "def load_and_preprocess_data(data_path, image_size=(224, 224)):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Loop through subfolders (class directories)\n",
        "    for class_name in os.listdir(data_path):\n",
        "        class_path = os.path.join(data_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            label = int(class_name)  # Assuming class folders are named with class indices\n",
        "            for image_filename in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_filename)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is not None:\n",
        "                    image = cv2.resize(image, image_size)  # Resize to a consistent size\n",
        "                    image = image.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "                    image_paths.append(image_path)\n",
        "                    labels.append(label)\n",
        "\n",
        "    return np.array(image_paths), np.array(labels)\n",
        "\n",
        "\n",
        "x_train, y_train = load_and_preprocess_data(data_path)\n",
        "\n",
        "# Use the get_three_classes function to filter the data\n",
        "x_train, y_train = get_three_classes(x_train, y_train)\n",
        "\n",
        "# Print the shapes\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "\n",
        "# Assuming data stored in x_train and y_train\n",
        "# The shapes are (2618,) for x_train and (2618, 2) for y_train\n",
        "\n",
        "# Determine the number of samples\n",
        "num_samples = len(x_train)\n",
        "\n",
        "# Set the random seed for reproducibility (optional)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate random indices for splitting the data\n",
        "indices = np.arange(num_samples)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Define the split ratio (e.g., 80% training, 20% validation)\n",
        "split_ratio = 0.8\n",
        "split_index = int(split_ratio * num_samples)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train_split = x_train[indices[:split_index]]\n",
        "y_train_split = y_train[indices[:split_index]]\n",
        "x_val_split = x_train[indices[split_index:]]\n",
        "y_val_split = y_train[indices[split_index:]]\n",
        "\n",
        "# Print the shapes of the splits\n",
        "print(\"Training data shapes:\")\n",
        "print(\"x_train_split shape:\", x_train_split.shape)\n",
        "print(\"y_train_split shape:\", y_train_split.shape)\n",
        "print(\"\\nValidation data shapes:\")\n",
        "print(\"x_val_split shape:\", x_val_split.shape)\n",
        "print(\"y_val_split shape:\", y_val_split.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Augmentation\n",
        "# Define a list to store augmented images and their corresponding labels\n",
        "augmented_X_train = []\n",
        "augmented_y_train = []\n",
        "\n",
        "# Apply data augmentation to each image in X_train\n",
        "for image_path, label in zip(x_train_split, y_train_split):\n",
        "    image = tf.io.read_file(image_path)  # Read the image file\n",
        "    image = tf.image.decode_image(image, channels=3)  # Decode image and set the number of channels\n",
        "    image = data_augmen2(image)  # Apply data augmentation\n",
        "    augmented_X_train.append(image)\n",
        "    augmented_y_train.append(label)\n",
        "\n",
        "# Convert lists to TensorFlow tensors\n",
        "augmented_X_train = tf.convert_to_tensor(augmented_X_train)\n",
        "augmented_y_train = tf.convert_to_tensor(augmented_y_train)\n",
        "\n",
        "# Print the shape of augmented data\n",
        "print(\"Shape of augmented X_train:\", augmented_X_train.shape)\n",
        "print(\"Shape of augmented y_train:\", augmented_y_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define a list to store the original validation images and their corresponding labels\n",
        "original_X_val = []\n",
        "original_y_val = []\n",
        "\n",
        "# Load the original validation data (without augmentation)\n",
        "for image_path, label in zip(x_val_split, y_val_split):\n",
        "    image = tf.io.read_file(image_path)  # Read the image file\n",
        "    image = tf.image.decode_image(image, channels=3)  # Decode image and set the number of channels\n",
        "    original_X_val.append(image)\n",
        "    original_y_val.append(label)\n",
        "\n",
        "# Convert lists to TensorFlow tensors\n",
        "original_X_val = tf.convert_to_tensor(original_X_val)\n",
        "original_y_val = tf.convert_to_tensor(original_y_val)\n",
        "\n",
        "# Print the shape of the original validation data\n",
        "print(\"Shape of original X_val:\", original_X_val.shape)\n",
        "print(\"Shape of original y_val:\", original_y_val.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}